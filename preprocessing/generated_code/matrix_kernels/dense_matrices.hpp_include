// @file
// This file is part of SeisSol.
// 
// @author Alexander Breuer (breuera AT in.tum.de, http://www5.in.tum.de/wiki/index.php/Dipl.-Math._Alexander_Breuer)
// @author Alexander Heinecke (heinecke AT in.tum.de, http://www5.in.tum.de/wiki/index.php/Alexander_Heinecke,_M.Sc.,_M.Sc._with_honors)
// 
// @date 2014-03-10 17:03:01.466770
// 
// @section LICENSE
// This software was developed at Technische Universitaet Muenchen, who is the owner of the software.
// 
// According to good scientific practice, publications on results achieved in whole or in part due to this software should cite at least one paper or referring to an URL presenting this software.
// 
// The owner wishes to make the software available to all users to use, reproduce, modify, distribute and redistribute also for commercial purposes under the following conditions of the original BSD license. Linking this software module statically or dynamically with other modules is making a combined work based on this software. Thus, the terms and conditions of this license cover the whole combination. As a special exception, the copyright holders of this software give you permission to link it with independent modules or to instantiate templates and macros from this software's source files to produce an executable, regardless of the license terms of these independent modules, and to copy and distribute the resulting executable under terms of your choice, provided that you also meet, for each linked independent module, the terms and conditions of this license of that module.
// 
// Copyright (c) 2012, 2013
// Technische Universitaet Muenchen
// Department of Informatics
// Chair of Scientific Computing
// http://www5.in.tum.de/
// 
// All rights reserved.
// 
// Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
// 
// Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
// Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
// All advertising materials mentioning features or use of this software must display the following acknowledgement: This product includes software developed by the Technische Universitaet Muenchen (TUM), Germany, and its contributors.
// Neither the name of the Technische Universitaet Muenchen, Munich, Germany nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
// 
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
// 
// @section DESCRIPTION
// Remark: This file was generated.
#ifndef DENSEMATRICESHPPINCLUDE
#define DENSEMATRICESHPPINCLUDE

#if defined( __SSE3__) || defined(__MIC__)
#include <immintrin.h>
#endif

inline void generatedMatrixMultiplication_dense_4_9_4(double* A, double* B, double* C, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+4;
double* c2 = C+8;
for(int n = 0; n < 9; n+=3)
{
  for(int m = 0; m < 0; m+=6)
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
    c_2_0 = _mm_setzero_pd();
    c_2_1 = _mm_setzero_pd();
    c_2_2 = _mm_setzero_pd();

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    _mm_store_pd(c0+4, c_2_0);
    _mm_store_pd(c1+4, c_2_1);
    _mm_store_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  for(int m = 0; m < 4; m+=4)
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = 4; m < 4; m+=2)
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = 4; m < 4; m++)
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=8;
  c1+=8;
  c2+=8;
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+4;
double* c2 = C+8;
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  for(int m = 0; m < 0; m+=16)
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();
    c_3_0 = _mm256_setzero_pd();
    c_3_1 = _mm256_setzero_pd();
    c_3_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    _mm256_store_pd(c0+12, c_3_0);
    _mm256_store_pd(c1+12, c_3_1);
    _mm256_store_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  for(int m = 0; m < 0; m+=12)
#else
  for(int m = 0; m < 0; m+=12)
#endif
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
#ifdef __AVX2__
  for(int m = 0; m < 0; m+=8)
#else
  for(int m = 0; m < 0; m+=8)
#endif
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
#ifdef __AVX2__
  for(int m = 0; m < 4; m+=4)
#else
  for(int m = 0; m < 4; m+=4)
#endif
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
#ifdef __AVX2__
  for(int m = 4; m < 4; m++)
#else
  for(int m = 4; m < 4; m++)
#endif
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0_128 = _mm_setzero_pd();
    c_0_1_128 = _mm_setzero_pd();
    c_0_2_128 = _mm_setzero_pd();
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=8;
  c1+=8;
  c2+=8;
}

#endif

#if !defined(__SSE3__) && !defined(__AVX__)
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < 4; k++)
  {
    for(int m = 0; m < 4; m++)
    {
      C[(n*4)+m] += A[(k*4)+m] * B[(n*4)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 288;
#endif

}

inline void generatedMatrixMultiplication_denseAder_4_9_4(double* A, double* B, double* C, int exit_col, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+4;
double* c2 = C+8;
int M = 2;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 36;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 10;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 2;
    break;
}
for(int n = 0; n < 9; n+=3)
{
  int mDone, mDone_old;
  mDone = (M/6)*6;
  for(int m = 0; m < mDone; m+=6)
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
    c_2_0 = _mm_setzero_pd();
    c_2_1 = _mm_setzero_pd();
    c_2_2 = _mm_setzero_pd();

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    _mm_store_pd(c0+4, c_2_0);
    _mm_store_pd(c1+4, c_2_1);
    _mm_store_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/4)*4);
  for(int m = mDone_old; m < mDone; m+=4)
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/2)*2);
  for(int m = mDone_old; m < mDone; m+=2)
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = mDone; m < M; m++)
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=(8+(4-M));
  c1+=(8+(4-M));
  c2+=(8+(4-M));
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+4;
double* c2 = C+8;
int M = 4;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 36;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 12;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 4;
    break;
}
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  int mDone, mDone_old;
  mDone = (M/16)*16;
  for(int m = 0; m < mDone; m+=16)
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();
    c_3_0 = _mm256_setzero_pd();
    c_3_1 = _mm256_setzero_pd();
    c_3_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    _mm256_store_pd(c0+12, c_3_0);
    _mm256_store_pd(c1+12, c_3_1);
    _mm256_store_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/12)*12);
  for(int m = mDone_old; m < mDone; m+=12)
#else
  int mDone, mDone_old;
  mDone = (M/12)*12;
  for(int m = 0; m < mDone; m+=12)
#endif
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/8)*8);
  for(int m = mDone_old; m < mDone; m+=8)
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/4)*4);
  for(int m = mDone_old; m < mDone; m+=4)
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = mDone; m < M; m++)
  {
    double* b0 = B+(n*4);
    double* b1 = B+((n+1)*4);
    double* b2 = B+((n+2)*4);
    double* a0 = A+m;
    c_0_0_128 = _mm_setzero_pd();
    c_0_1_128 = _mm_setzero_pd();
    c_0_2_128 = _mm_setzero_pd();
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=(8+(4-M));
  c1+=(8+(4-M));
  c2+=(8+(4-M));
}

#endif

#if !defined(__SSE3__) && !defined(__AVX__)
int M = 4;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 35;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 10;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 4;
    break;
}
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < exit_col; k++)
  {
    for(int m = 0; m < M; m++)
    {
      C[(n*4)+m] += A[(k*4)+m] * B[(n*4)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 18*M*exit_col;
#endif

}

inline void generatedMatrixMultiplication_dense_4_9_9(double* A, double* B, double* C, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+4;
double* c2 = C+8;
for(int n = 0; n < 9; n+=3)
{
  for(int m = 0; m < 0; m+=6)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_pd(c0);
    c_0_1 = _mm_load_pd(c1);
    c_0_2 = _mm_load_pd(c2);
    c_1_0 = _mm_load_pd(c0+2);
    c_1_1 = _mm_load_pd(c1+2);
    c_1_2 = _mm_load_pd(c2+2);
    c_2_0 = _mm_load_pd(c0+4);
    c_2_1 = _mm_load_pd(c1+4);
    c_2_2 = _mm_load_pd(c2+4);

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=0;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    _mm_store_pd(c0+4, c_2_0);
    _mm_store_pd(c1+4, c_2_1);
    _mm_store_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  for(int m = 0; m < 4; m+=4)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_pd(c0);
    c_0_1 = _mm_load_pd(c1);
    c_0_2 = _mm_load_pd(c2);
    c_1_0 = _mm_load_pd(c0+2);
    c_1_1 = _mm_load_pd(c1+2);
    c_1_2 = _mm_load_pd(c2+2);
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = 4; m < 4; m+=2)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_pd(c0);
    c_0_1 = _mm_load_pd(c1);
    c_0_2 = _mm_load_pd(c2);
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=4;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = 4; m < 4; m++)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_sd(c0);
    c_0_1 = _mm_load_sd(c1);
    c_0_2 = _mm_load_sd(c2);
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=4;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=8;
  c1+=8;
  c2+=8;
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+4;
double* c2 = C+8;
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  for(int m = 0; m < 0; m+=16)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
    c_1_0 = _mm256_load_pd(c0+4);
    c_1_1 = _mm256_load_pd(c1+4);
    c_1_2 = _mm256_load_pd(c2+4);
    c_2_0 = _mm256_load_pd(c0+8);
    c_2_1 = _mm256_load_pd(c1+8);
    c_2_2 = _mm256_load_pd(c2+8);
    c_3_0 = _mm256_load_pd(c0+12);
    c_3_1 = _mm256_load_pd(c1+12);
    c_3_2 = _mm256_load_pd(c2+12);

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    _mm256_store_pd(c0+12, c_3_0);
    _mm256_store_pd(c1+12, c_3_1);
    _mm256_store_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  for(int m = 0; m < 0; m+=12)
#else
  for(int m = 0; m < 0; m+=12)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
    c_1_0 = _mm256_load_pd(c0+4);
    c_1_1 = _mm256_load_pd(c1+4);
    c_1_2 = _mm256_load_pd(c2+4);
    c_2_0 = _mm256_load_pd(c0+8);
    c_2_1 = _mm256_load_pd(c1+8);
    c_2_2 = _mm256_load_pd(c2+8);

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=-4;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
#ifdef __AVX2__
  for(int m = 0; m < 0; m+=8)
#else
  for(int m = 0; m < 0; m+=8)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
    c_1_0 = _mm256_load_pd(c0+4);
    c_1_1 = _mm256_load_pd(c1+4);
    c_1_2 = _mm256_load_pd(c2+4);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=0;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
#ifdef __AVX2__
  for(int m = 0; m < 4; m+=4)
#else
  for(int m = 0; m < 4; m+=4)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
#ifdef __AVX2__
  for(int m = 4; m < 4; m++)
#else
  for(int m = 4; m < 4; m++)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0_128 = _mm_load_sd(c0);
    c_0_1_128 = _mm_load_sd(c1);
    c_0_2_128 = _mm_load_sd(c2);
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=8;
  c1+=8;
  c2+=8;
}

#endif

#if !defined(__SSE3__) && !defined(__AVX__)
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < 9; k++)
  {
    for(int m = 0; m < 4; m++)
    {
      C[(n*4)+m] += A[(k*4)+m] * B[(n*9)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 648;
#endif

}

inline void generatedMatrixMultiplication_dense_10_9_10(double* A, double* B, double* C, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+10;
double* c2 = C+20;
for(int n = 0; n < 9; n+=3)
{
  for(int m = 0; m < 6; m+=6)
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
    c_2_0 = _mm_setzero_pd();
    c_2_1 = _mm_setzero_pd();
    c_2_2 = _mm_setzero_pd();

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    _mm_store_pd(c0+4, c_2_0);
    _mm_store_pd(c1+4, c_2_1);
    _mm_store_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  for(int m = 6; m < 10; m+=4)
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = 10; m < 10; m+=2)
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = 10; m < 10; m++)
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=20;
  c1+=20;
  c2+=20;
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+10;
double* c2 = C+20;
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  for(int m = 0; m < 0; m+=16)
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();
    c_3_0 = _mm256_setzero_pd();
    c_3_1 = _mm256_setzero_pd();
    c_3_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    _mm256_store_pd(c0+12, c_3_0);
    _mm256_store_pd(c1+12, c_3_1);
    _mm256_store_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  for(int m = 0; m < 0; m+=12)
#else
  for(int m = 0; m < 0; m+=12)
#endif
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
#ifdef __AVX2__
  for(int m = 0; m < 8; m+=8)
#else
  for(int m = 0; m < 8; m+=8)
#endif
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
#ifdef __AVX2__
  for(int m = 8; m < 8; m+=4)
#else
  for(int m = 8; m < 8; m+=4)
#endif
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
#ifdef __AVX2__
  for(int m = 8; m < 10; m++)
#else
  for(int m = 8; m < 10; m++)
#endif
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0_128 = _mm_setzero_pd();
    c_0_1_128 = _mm_setzero_pd();
    c_0_2_128 = _mm_setzero_pd();
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=20;
  c1+=20;
  c2+=20;
}

#endif

#if !defined(__SSE3__) && !defined(__AVX__)
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < 10; k++)
  {
    for(int m = 0; m < 10; m++)
    {
      C[(n*10)+m] += A[(k*10)+m] * B[(n*10)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 1800;
#endif

}

inline void generatedMatrixMultiplication_denseAder_10_9_10(double* A, double* B, double* C, int exit_col, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+10;
double* c2 = C+20;
int M = 2;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 36;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 10;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 2;
    break;
}
for(int n = 0; n < 9; n+=3)
{
  int mDone, mDone_old;
  mDone = (M/6)*6;
  for(int m = 0; m < mDone; m+=6)
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
    c_2_0 = _mm_setzero_pd();
    c_2_1 = _mm_setzero_pd();
    c_2_2 = _mm_setzero_pd();

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_six_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

sse_six_end:
    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    _mm_store_pd(c0+4, c_2_0);
    _mm_store_pd(c1+4, c_2_1);
    _mm_store_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/4)*4);
  for(int m = mDone_old; m < mDone; m+=4)
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_four_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

sse_four_end:
    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/2)*2);
  for(int m = mDone_old; m < mDone; m+=2)
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_two_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

sse_two_end:
    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = mDone; m < M; m++)
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_one_end; }
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

sse_one_end:
    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=(20+(10-M));
  c1+=(20+(10-M));
  c2+=(20+(10-M));
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+10;
double* c2 = C+20;
int M = 4;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 36;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 12;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 4;
    break;
}
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  int mDone, mDone_old;
  mDone = (M/16)*16;
  for(int m = 0; m < mDone; m+=16)
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();
    c_3_0 = _mm256_setzero_pd();
    c_3_1 = _mm256_setzero_pd();
    c_3_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_sixteen_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
avx_sixteen_end:
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    _mm256_store_pd(c0+12, c_3_0);
    _mm256_store_pd(c1+12, c_3_1);
    _mm256_store_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/12)*12);
  for(int m = mDone_old; m < mDone; m+=12)
#else
  int mDone, mDone_old;
  mDone = (M/12)*12;
  for(int m = 0; m < mDone; m+=12)
#endif
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_twelve_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

avx_twelve_end:
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/8)*8);
  for(int m = mDone_old; m < mDone; m+=8)
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_eight_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

avx_eight_end:
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/4)*4);
  for(int m = mDone_old; m < mDone; m+=4)
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_four_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

avx_four_end:
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = mDone; m < M; m++)
  {
    double* b0 = B+(n*10);
    double* b1 = B+((n+1)*10);
    double* b2 = B+((n+2)*10);
    double* a0 = A+m;
    c_0_0_128 = _mm_setzero_pd();
    c_0_1_128 = _mm_setzero_pd();
    c_0_2_128 = _mm_setzero_pd();
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_one_end; }
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

avx_one_end:
    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=(20+(10-M));
  c1+=(20+(10-M));
  c2+=(20+(10-M));
}

#endif

#if !defined(__SSE3__) && !defined(__AVX__)
int M = 4;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 35;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 10;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 4;
    break;
}
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < exit_col; k++)
  {
    for(int m = 0; m < M; m++)
    {
      C[(n*10)+m] += A[(k*10)+m] * B[(n*10)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 18*M*exit_col;
#endif

}

inline void generatedMatrixMultiplication_dense_10_9_9(double* A, double* B, double* C, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+10;
double* c2 = C+20;
for(int n = 0; n < 9; n+=3)
{
  for(int m = 0; m < 6; m+=6)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_pd(c0);
    c_0_1 = _mm_load_pd(c1);
    c_0_2 = _mm_load_pd(c2);
    c_1_0 = _mm_load_pd(c0+2);
    c_1_1 = _mm_load_pd(c1+2);
    c_1_2 = _mm_load_pd(c2+2);
    c_2_0 = _mm_load_pd(c0+4);
    c_2_1 = _mm_load_pd(c1+4);
    c_2_2 = _mm_load_pd(c2+4);

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=6;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    _mm_store_pd(c0+4, c_2_0);
    _mm_store_pd(c1+4, c_2_1);
    _mm_store_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  for(int m = 6; m < 10; m+=4)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_pd(c0);
    c_0_1 = _mm_load_pd(c1);
    c_0_2 = _mm_load_pd(c2);
    c_1_0 = _mm_load_pd(c0+2);
    c_1_1 = _mm_load_pd(c1+2);
    c_1_2 = _mm_load_pd(c2+2);
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=8;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = 10; m < 10; m+=2)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_pd(c0);
    c_0_1 = _mm_load_pd(c1);
    c_0_2 = _mm_load_pd(c2);
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=10;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = 10; m < 10; m++)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_sd(c0);
    c_0_1 = _mm_load_sd(c1);
    c_0_2 = _mm_load_sd(c2);
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=10;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=20;
  c1+=20;
  c2+=20;
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+10;
double* c2 = C+20;
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  for(int m = 0; m < 0; m+=16)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
    c_1_0 = _mm256_load_pd(c0+4);
    c_1_1 = _mm256_load_pd(c1+4);
    c_1_2 = _mm256_load_pd(c2+4);
    c_2_0 = _mm256_load_pd(c0+8);
    c_2_1 = _mm256_load_pd(c1+8);
    c_2_2 = _mm256_load_pd(c2+8);
    c_3_0 = _mm256_load_pd(c0+12);
    c_3_1 = _mm256_load_pd(c1+12);
    c_3_2 = _mm256_load_pd(c2+12);

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=-2;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    _mm256_store_pd(c0+12, c_3_0);
    _mm256_store_pd(c1+12, c_3_1);
    _mm256_store_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  for(int m = 0; m < 0; m+=12)
#else
  for(int m = 0; m < 0; m+=12)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
    c_1_0 = _mm256_load_pd(c0+4);
    c_1_1 = _mm256_load_pd(c1+4);
    c_1_2 = _mm256_load_pd(c2+4);
    c_2_0 = _mm256_load_pd(c0+8);
    c_2_1 = _mm256_load_pd(c1+8);
    c_2_2 = _mm256_load_pd(c2+8);

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=2;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
#ifdef __AVX2__
  for(int m = 0; m < 8; m+=8)
#else
  for(int m = 0; m < 8; m+=8)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
    c_1_0 = _mm256_load_pd(c0+4);
    c_1_1 = _mm256_load_pd(c1+4);
    c_1_2 = _mm256_load_pd(c2+4);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=6;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
#ifdef __AVX2__
  for(int m = 8; m < 8; m+=4)
#else
  for(int m = 8; m < 8; m+=4)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
#ifdef __AVX2__
  for(int m = 8; m < 10; m++)
#else
  for(int m = 8; m < 10; m++)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0_128 = _mm_load_sd(c0);
    c_0_1_128 = _mm_load_sd(c1);
    c_0_2_128 = _mm_load_sd(c2);
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=10;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=20;
  c1+=20;
  c2+=20;
}

#endif

#if !defined(__SSE3__) && !defined(__AVX__)
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < 9; k++)
  {
    for(int m = 0; m < 10; m++)
    {
      C[(n*10)+m] += A[(k*10)+m] * B[(n*9)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 1620;
#endif

}

inline void generatedMatrixMultiplication_dense_20_9_20(double* A, double* B, double* C, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+20;
double* c2 = C+40;
for(int n = 0; n < 9; n+=3)
{
  for(int m = 0; m < 18; m+=6)
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
    c_2_0 = _mm_setzero_pd();
    c_2_1 = _mm_setzero_pd();
    c_2_2 = _mm_setzero_pd();

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    _mm_store_pd(c0+4, c_2_0);
    _mm_store_pd(c1+4, c_2_1);
    _mm_store_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  for(int m = 18; m < 18; m+=4)
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = 18; m < 20; m+=2)
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = 20; m < 20; m++)
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=40;
  c1+=40;
  c2+=40;
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+20;
double* c2 = C+40;
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  for(int m = 0; m < 16; m+=16)
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();
    c_3_0 = _mm256_setzero_pd();
    c_3_1 = _mm256_setzero_pd();
    c_3_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    _mm256_store_pd(c0+12, c_3_0);
    _mm256_store_pd(c1+12, c_3_1);
    _mm256_store_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  for(int m = 16; m < 16; m+=12)
#else
  for(int m = 0; m < 12; m+=12)
#endif
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
#ifdef __AVX2__
  for(int m = 16; m < 16; m+=8)
#else
  for(int m = 12; m < 20; m+=8)
#endif
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
#ifdef __AVX2__
  for(int m = 16; m < 20; m+=4)
#else
  for(int m = 20; m < 20; m+=4)
#endif
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
#ifdef __AVX2__
  for(int m = 20; m < 20; m++)
#else
  for(int m = 20; m < 20; m++)
#endif
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0_128 = _mm_setzero_pd();
    c_0_1_128 = _mm_setzero_pd();
    c_0_2_128 = _mm_setzero_pd();
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=40;
  c1+=40;
  c2+=40;
}

#endif

#if !defined(__SSE3__) && !defined(__AVX__)
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < 20; k++)
  {
    for(int m = 0; m < 20; m++)
    {
      C[(n*20)+m] += A[(k*20)+m] * B[(n*20)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 7200;
#endif

}

inline void generatedMatrixMultiplication_denseAder_20_9_20(double* A, double* B, double* C, int exit_col, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+20;
double* c2 = C+40;
int M = 2;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 36;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 10;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 2;
    break;
}
for(int n = 0; n < 9; n+=3)
{
  int mDone, mDone_old;
  mDone = (M/6)*6;
  for(int m = 0; m < mDone; m+=6)
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
    c_2_0 = _mm_setzero_pd();
    c_2_1 = _mm_setzero_pd();
    c_2_2 = _mm_setzero_pd();

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_six_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      if ( __builtin_expect(exit_col == 10, false) ) { goto sse_six_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

sse_six_end:
    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    _mm_store_pd(c0+4, c_2_0);
    _mm_store_pd(c1+4, c_2_1);
    _mm_store_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/4)*4);
  for(int m = mDone_old; m < mDone; m+=4)
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_four_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      if ( __builtin_expect(exit_col == 10, false) ) { goto sse_four_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

sse_four_end:
    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/2)*2);
  for(int m = mDone_old; m < mDone; m+=2)
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_two_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      if ( __builtin_expect(exit_col == 10, false) ) { goto sse_two_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

sse_two_end:
    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = mDone; m < M; m++)
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_one_end; }
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      if ( __builtin_expect(exit_col == 10, false) ) { goto sse_one_end; }
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

sse_one_end:
    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=(40+(20-M));
  c1+=(40+(20-M));
  c2+=(40+(20-M));
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+20;
double* c2 = C+40;
int M = 4;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 36;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 12;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 4;
    break;
}
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  int mDone, mDone_old;
  mDone = (M/16)*16;
  for(int m = 0; m < mDone; m+=16)
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();
    c_3_0 = _mm256_setzero_pd();
    c_3_1 = _mm256_setzero_pd();
    c_3_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_sixteen_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_sixteen_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
avx_sixteen_end:
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    _mm256_store_pd(c0+12, c_3_0);
    _mm256_store_pd(c1+12, c_3_1);
    _mm256_store_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/12)*12);
  for(int m = mDone_old; m < mDone; m+=12)
#else
  int mDone, mDone_old;
  mDone = (M/12)*12;
  for(int m = 0; m < mDone; m+=12)
#endif
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_twelve_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_twelve_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

avx_twelve_end:
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/8)*8);
  for(int m = mDone_old; m < mDone; m+=8)
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_eight_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_eight_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

avx_eight_end:
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/4)*4);
  for(int m = mDone_old; m < mDone; m+=4)
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_four_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_four_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

avx_four_end:
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = mDone; m < M; m++)
  {
    double* b0 = B+(n*20);
    double* b1 = B+((n+1)*20);
    double* b2 = B+((n+2)*20);
    double* a0 = A+m;
    c_0_0_128 = _mm_setzero_pd();
    c_0_1_128 = _mm_setzero_pd();
    c_0_2_128 = _mm_setzero_pd();
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_one_end; }
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_one_end; }
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

avx_one_end:
    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=(40+(20-M));
  c1+=(40+(20-M));
  c2+=(40+(20-M));
}

#endif

#if !defined(__SSE3__) && !defined(__AVX__)
int M = 4;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 35;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 10;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 4;
    break;
}
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < exit_col; k++)
  {
    for(int m = 0; m < M; m++)
    {
      C[(n*20)+m] += A[(k*20)+m] * B[(n*20)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 18*M*exit_col;
#endif

}

inline void generatedMatrixMultiplication_dense_20_9_9(double* A, double* B, double* C, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+20;
double* c2 = C+40;
for(int n = 0; n < 9; n+=3)
{
  for(int m = 0; m < 18; m+=6)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_pd(c0);
    c_0_1 = _mm_load_pd(c1);
    c_0_2 = _mm_load_pd(c2);
    c_1_0 = _mm_load_pd(c0+2);
    c_1_1 = _mm_load_pd(c1+2);
    c_1_2 = _mm_load_pd(c2+2);
    c_2_0 = _mm_load_pd(c0+4);
    c_2_1 = _mm_load_pd(c1+4);
    c_2_2 = _mm_load_pd(c2+4);

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=16;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    _mm_store_pd(c0+4, c_2_0);
    _mm_store_pd(c1+4, c_2_1);
    _mm_store_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  for(int m = 18; m < 18; m+=4)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_pd(c0);
    c_0_1 = _mm_load_pd(c1);
    c_0_2 = _mm_load_pd(c2);
    c_1_0 = _mm_load_pd(c0+2);
    c_1_1 = _mm_load_pd(c1+2);
    c_1_2 = _mm_load_pd(c2+2);
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=18;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = 18; m < 20; m+=2)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_pd(c0);
    c_0_1 = _mm_load_pd(c1);
    c_0_2 = _mm_load_pd(c2);
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=20;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = 20; m < 20; m++)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_sd(c0);
    c_0_1 = _mm_load_sd(c1);
    c_0_2 = _mm_load_sd(c2);
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=20;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=40;
  c1+=40;
  c2+=40;
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+20;
double* c2 = C+40;
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  for(int m = 0; m < 16; m+=16)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
    c_1_0 = _mm256_load_pd(c0+4);
    c_1_1 = _mm256_load_pd(c1+4);
    c_1_2 = _mm256_load_pd(c2+4);
    c_2_0 = _mm256_load_pd(c0+8);
    c_2_1 = _mm256_load_pd(c1+8);
    c_2_2 = _mm256_load_pd(c2+8);
    c_3_0 = _mm256_load_pd(c0+12);
    c_3_1 = _mm256_load_pd(c1+12);
    c_3_2 = _mm256_load_pd(c2+12);

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=8;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    _mm256_store_pd(c0+12, c_3_0);
    _mm256_store_pd(c1+12, c_3_1);
    _mm256_store_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  for(int m = 16; m < 16; m+=12)
#else
  for(int m = 0; m < 12; m+=12)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
    c_1_0 = _mm256_load_pd(c0+4);
    c_1_1 = _mm256_load_pd(c1+4);
    c_1_2 = _mm256_load_pd(c2+4);
    c_2_0 = _mm256_load_pd(c0+8);
    c_2_1 = _mm256_load_pd(c1+8);
    c_2_2 = _mm256_load_pd(c2+8);

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=12;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
#ifdef __AVX2__
  for(int m = 16; m < 16; m+=8)
#else
  for(int m = 12; m < 20; m+=8)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
    c_1_0 = _mm256_load_pd(c0+4);
    c_1_1 = _mm256_load_pd(c1+4);
    c_1_2 = _mm256_load_pd(c2+4);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=16;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
#ifdef __AVX2__
  for(int m = 16; m < 20; m+=4)
#else
  for(int m = 20; m < 20; m+=4)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
#ifdef __AVX2__
  for(int m = 20; m < 20; m++)
#else
  for(int m = 20; m < 20; m++)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0_128 = _mm_load_sd(c0);
    c_0_1_128 = _mm_load_sd(c1);
    c_0_2_128 = _mm_load_sd(c2);
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=20;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=40;
  c1+=40;
  c2+=40;
}

#endif

#if !defined(__SSE3__) && !defined(__AVX__)
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < 9; k++)
  {
    for(int m = 0; m < 20; m++)
    {
      C[(n*20)+m] += A[(k*20)+m] * B[(n*9)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 3240;
#endif

}

inline void generatedMatrixMultiplication_dense_35_9_35(double* A, double* B, double* C, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+35;
double* c2 = C+70;
for(int n = 0; n < 9; n+=3)
{
  for(int m = 0; m < 30; m+=6)
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
    c_2_0 = _mm_setzero_pd();
    c_2_1 = _mm_setzero_pd();
    c_2_2 = _mm_setzero_pd();

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

    _mm_storeu_pd(c0, c_0_0);
    _mm_storeu_pd(c1, c_0_1);
    _mm_storeu_pd(c2, c_0_2);
    _mm_storeu_pd(c0+2, c_1_0);
    _mm_storeu_pd(c1+2, c_1_1);
    _mm_storeu_pd(c2+2, c_1_2);
    _mm_storeu_pd(c0+4, c_2_0);
    _mm_storeu_pd(c1+4, c_2_1);
    _mm_storeu_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  for(int m = 30; m < 34; m+=4)
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

    _mm_storeu_pd(c0, c_0_0);
    _mm_storeu_pd(c1, c_0_1);
    _mm_storeu_pd(c2, c_0_2);
    _mm_storeu_pd(c0+2, c_1_0);
    _mm_storeu_pd(c1+2, c_1_1);
    _mm_storeu_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = 34; m < 34; m+=2)
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

    _mm_storeu_pd(c0, c_0_0);
    _mm_storeu_pd(c1, c_0_1);
    _mm_storeu_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = 34; m < 35; m++)
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=70;
  c1+=70;
  c2+=70;
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+35;
double* c2 = C+70;
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  for(int m = 0; m < 32; m+=16)
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();
    c_3_0 = _mm256_setzero_pd();
    c_3_1 = _mm256_setzero_pd();
    c_3_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
    _mm256_storeu_pd(c0, c_0_0);
    _mm256_storeu_pd(c1, c_0_1);
    _mm256_storeu_pd(c2, c_0_2);
    _mm256_storeu_pd(c0+4, c_1_0);
    _mm256_storeu_pd(c1+4, c_1_1);
    _mm256_storeu_pd(c2+4, c_1_2);
    _mm256_storeu_pd(c0+8, c_2_0);
    _mm256_storeu_pd(c1+8, c_2_1);
    _mm256_storeu_pd(c2+8, c_2_2);
    _mm256_storeu_pd(c0+12, c_3_0);
    _mm256_storeu_pd(c1+12, c_3_1);
    _mm256_storeu_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  for(int m = 32; m < 32; m+=12)
#else
  for(int m = 0; m < 24; m+=12)
#endif
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

    _mm256_storeu_pd(c0, c_0_0);
    _mm256_storeu_pd(c1, c_0_1);
    _mm256_storeu_pd(c2, c_0_2);
    _mm256_storeu_pd(c0+4, c_1_0);
    _mm256_storeu_pd(c1+4, c_1_1);
    _mm256_storeu_pd(c2+4, c_1_2);
    _mm256_storeu_pd(c0+8, c_2_0);
    _mm256_storeu_pd(c1+8, c_2_1);
    _mm256_storeu_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
#ifdef __AVX2__
  for(int m = 32; m < 32; m+=8)
#else
  for(int m = 24; m < 32; m+=8)
#endif
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

    _mm256_storeu_pd(c0, c_0_0);
    _mm256_storeu_pd(c1, c_0_1);
    _mm256_storeu_pd(c2, c_0_2);
    _mm256_storeu_pd(c0+4, c_1_0);
    _mm256_storeu_pd(c1+4, c_1_1);
    _mm256_storeu_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
#ifdef __AVX2__
  for(int m = 32; m < 32; m+=4)
#else
  for(int m = 32; m < 32; m+=4)
#endif
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

    _mm256_storeu_pd(c0, c_0_0);
    _mm256_storeu_pd(c1, c_0_1);
    _mm256_storeu_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
#ifdef __AVX2__
  for(int m = 32; m < 35; m++)
#else
  for(int m = 32; m < 35; m++)
#endif
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0_128 = _mm_setzero_pd();
    c_0_1_128 = _mm_setzero_pd();
    c_0_2_128 = _mm_setzero_pd();
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=70;
  c1+=70;
  c2+=70;
}

#endif

#if !defined(__SSE3__) && !defined(__AVX__)
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < 35; k++)
  {
    for(int m = 0; m < 35; m++)
    {
      C[(n*35)+m] += A[(k*35)+m] * B[(n*35)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 22050;
#endif

}

inline void generatedMatrixMultiplication_denseAder_35_9_35(double* A, double* B, double* C, int exit_col, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+35;
double* c2 = C+70;
int M = 2;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 36;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 10;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 2;
    break;
}
for(int n = 0; n < 9; n+=3)
{
  int mDone, mDone_old;
  mDone = (M/6)*6;
  for(int m = 0; m < mDone; m+=6)
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
    c_2_0 = _mm_setzero_pd();
    c_2_1 = _mm_setzero_pd();
    c_2_2 = _mm_setzero_pd();

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_six_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      if ( __builtin_expect(exit_col == 10, false) ) { goto sse_six_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      if ( __builtin_expect(exit_col == 20, false) ) { goto sse_six_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

sse_six_end:
    _mm_storeu_pd(c0, c_0_0);
    _mm_storeu_pd(c1, c_0_1);
    _mm_storeu_pd(c2, c_0_2);
    _mm_storeu_pd(c0+2, c_1_0);
    _mm_storeu_pd(c1+2, c_1_1);
    _mm_storeu_pd(c2+2, c_1_2);
    _mm_storeu_pd(c0+4, c_2_0);
    _mm_storeu_pd(c1+4, c_2_1);
    _mm_storeu_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/4)*4);
  for(int m = mDone_old; m < mDone; m+=4)
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_four_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      if ( __builtin_expect(exit_col == 10, false) ) { goto sse_four_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      if ( __builtin_expect(exit_col == 20, false) ) { goto sse_four_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

sse_four_end:
    _mm_storeu_pd(c0, c_0_0);
    _mm_storeu_pd(c1, c_0_1);
    _mm_storeu_pd(c2, c_0_2);
    _mm_storeu_pd(c0+2, c_1_0);
    _mm_storeu_pd(c1+2, c_1_1);
    _mm_storeu_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/2)*2);
  for(int m = mDone_old; m < mDone; m+=2)
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_two_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      if ( __builtin_expect(exit_col == 10, false) ) { goto sse_two_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      if ( __builtin_expect(exit_col == 20, false) ) { goto sse_two_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

sse_two_end:
    _mm_storeu_pd(c0, c_0_0);
    _mm_storeu_pd(c1, c_0_1);
    _mm_storeu_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = mDone; m < M; m++)
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_one_end; }
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      if ( __builtin_expect(exit_col == 10, false) ) { goto sse_one_end; }
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      if ( __builtin_expect(exit_col == 20, false) ) { goto sse_one_end; }
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

sse_one_end:
    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=(70+(35-M));
  c1+=(70+(35-M));
  c2+=(70+(35-M));
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+35;
double* c2 = C+70;
int M = 4;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 36;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 12;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 4;
    break;
}
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  int mDone, mDone_old;
  mDone = (M/16)*16;
  for(int m = 0; m < mDone; m+=16)
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();
    c_3_0 = _mm256_setzero_pd();
    c_3_1 = _mm256_setzero_pd();
    c_3_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_sixteen_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_sixteen_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      if ( __builtin_expect(exit_col == 20, false) ) { goto avx_sixteen_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
avx_sixteen_end:
    _mm256_storeu_pd(c0, c_0_0);
    _mm256_storeu_pd(c1, c_0_1);
    _mm256_storeu_pd(c2, c_0_2);
    _mm256_storeu_pd(c0+4, c_1_0);
    _mm256_storeu_pd(c1+4, c_1_1);
    _mm256_storeu_pd(c2+4, c_1_2);
    _mm256_storeu_pd(c0+8, c_2_0);
    _mm256_storeu_pd(c1+8, c_2_1);
    _mm256_storeu_pd(c2+8, c_2_2);
    _mm256_storeu_pd(c0+12, c_3_0);
    _mm256_storeu_pd(c1+12, c_3_1);
    _mm256_storeu_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/12)*12);
  for(int m = mDone_old; m < mDone; m+=12)
#else
  int mDone, mDone_old;
  mDone = (M/12)*12;
  for(int m = 0; m < mDone; m+=12)
#endif
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_twelve_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_twelve_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      if ( __builtin_expect(exit_col == 20, false) ) { goto avx_twelve_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

avx_twelve_end:
    _mm256_storeu_pd(c0, c_0_0);
    _mm256_storeu_pd(c1, c_0_1);
    _mm256_storeu_pd(c2, c_0_2);
    _mm256_storeu_pd(c0+4, c_1_0);
    _mm256_storeu_pd(c1+4, c_1_1);
    _mm256_storeu_pd(c2+4, c_1_2);
    _mm256_storeu_pd(c0+8, c_2_0);
    _mm256_storeu_pd(c1+8, c_2_1);
    _mm256_storeu_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/8)*8);
  for(int m = mDone_old; m < mDone; m+=8)
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_eight_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_eight_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      if ( __builtin_expect(exit_col == 20, false) ) { goto avx_eight_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

avx_eight_end:
    _mm256_storeu_pd(c0, c_0_0);
    _mm256_storeu_pd(c1, c_0_1);
    _mm256_storeu_pd(c2, c_0_2);
    _mm256_storeu_pd(c0+4, c_1_0);
    _mm256_storeu_pd(c1+4, c_1_1);
    _mm256_storeu_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/4)*4);
  for(int m = mDone_old; m < mDone; m+=4)
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_four_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_four_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      if ( __builtin_expect(exit_col == 20, false) ) { goto avx_four_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

avx_four_end:
    _mm256_storeu_pd(c0, c_0_0);
    _mm256_storeu_pd(c1, c_0_1);
    _mm256_storeu_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = mDone; m < M; m++)
  {
    double* b0 = B+(n*35);
    double* b1 = B+((n+1)*35);
    double* b2 = B+((n+2)*35);
    double* a0 = A+m;
    c_0_0_128 = _mm_setzero_pd();
    c_0_1_128 = _mm_setzero_pd();
    c_0_2_128 = _mm_setzero_pd();
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_one_end; }
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_one_end; }
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      if ( __builtin_expect(exit_col == 20, false) ) { goto avx_one_end; }
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

avx_one_end:
    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=(70+(35-M));
  c1+=(70+(35-M));
  c2+=(70+(35-M));
}

#endif

#if !defined(__SSE3__) && !defined(__AVX__)
int M = 4;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 35;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 10;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 4;
    break;
}
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < exit_col; k++)
  {
    for(int m = 0; m < M; m++)
    {
      C[(n*35)+m] += A[(k*35)+m] * B[(n*35)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 18*M*exit_col;
#endif

}

inline void generatedMatrixMultiplication_dense_35_9_9(double* A, double* B, double* C, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+35;
double* c2 = C+70;
for(int n = 0; n < 9; n+=3)
{
  for(int m = 0; m < 30; m+=6)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_loadu_pd(c0);
    c_0_1 = _mm_loadu_pd(c1);
    c_0_2 = _mm_loadu_pd(c2);
    c_1_0 = _mm_loadu_pd(c0+2);
    c_1_1 = _mm_loadu_pd(c1+2);
    c_1_2 = _mm_loadu_pd(c2+2);
    c_2_0 = _mm_loadu_pd(c0+4);
    c_2_1 = _mm_loadu_pd(c1+4);
    c_2_2 = _mm_loadu_pd(c2+4);

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_loadu_pd(a0);
      a0+=31;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

    _mm_storeu_pd(c0, c_0_0);
    _mm_storeu_pd(c1, c_0_1);
    _mm_storeu_pd(c2, c_0_2);
    _mm_storeu_pd(c0+2, c_1_0);
    _mm_storeu_pd(c1+2, c_1_1);
    _mm_storeu_pd(c2+2, c_1_2);
    _mm_storeu_pd(c0+4, c_2_0);
    _mm_storeu_pd(c1+4, c_2_1);
    _mm_storeu_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  for(int m = 30; m < 34; m+=4)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_loadu_pd(c0);
    c_0_1 = _mm_loadu_pd(c1);
    c_0_2 = _mm_loadu_pd(c2);
    c_1_0 = _mm_loadu_pd(c0+2);
    c_1_1 = _mm_loadu_pd(c1+2);
    c_1_2 = _mm_loadu_pd(c2+2);
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_loadu_pd(a0);
      a0+=33;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

    _mm_storeu_pd(c0, c_0_0);
    _mm_storeu_pd(c1, c_0_1);
    _mm_storeu_pd(c2, c_0_2);
    _mm_storeu_pd(c0+2, c_1_0);
    _mm_storeu_pd(c1+2, c_1_1);
    _mm_storeu_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = 34; m < 34; m+=2)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_loadu_pd(c0);
    c_0_1 = _mm_loadu_pd(c1);
    c_0_2 = _mm_loadu_pd(c2);
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_loadu_pd(a0);
      a0+=35;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

    _mm_storeu_pd(c0, c_0_0);
    _mm_storeu_pd(c1, c_0_1);
    _mm_storeu_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = 34; m < 35; m++)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_sd(c0);
    c_0_1 = _mm_load_sd(c1);
    c_0_2 = _mm_load_sd(c2);
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=35;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=70;
  c1+=70;
  c2+=70;
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+35;
double* c2 = C+70;
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  for(int m = 0; m < 32; m+=16)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_loadu_pd(c0);
    c_0_1 = _mm256_loadu_pd(c1);
    c_0_2 = _mm256_loadu_pd(c2);
    c_1_0 = _mm256_loadu_pd(c0+4);
    c_1_1 = _mm256_loadu_pd(c1+4);
    c_1_2 = _mm256_loadu_pd(c2+4);
    c_2_0 = _mm256_loadu_pd(c0+8);
    c_2_1 = _mm256_loadu_pd(c1+8);
    c_2_2 = _mm256_loadu_pd(c2+8);
    c_3_0 = _mm256_loadu_pd(c0+12);
    c_3_1 = _mm256_loadu_pd(c1+12);
    c_3_2 = _mm256_loadu_pd(c2+12);

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_loadu_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_loadu_pd(a0);
      a0+=23;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
    _mm256_storeu_pd(c0, c_0_0);
    _mm256_storeu_pd(c1, c_0_1);
    _mm256_storeu_pd(c2, c_0_2);
    _mm256_storeu_pd(c0+4, c_1_0);
    _mm256_storeu_pd(c1+4, c_1_1);
    _mm256_storeu_pd(c2+4, c_1_2);
    _mm256_storeu_pd(c0+8, c_2_0);
    _mm256_storeu_pd(c1+8, c_2_1);
    _mm256_storeu_pd(c2+8, c_2_2);
    _mm256_storeu_pd(c0+12, c_3_0);
    _mm256_storeu_pd(c1+12, c_3_1);
    _mm256_storeu_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  for(int m = 32; m < 32; m+=12)
#else
  for(int m = 0; m < 24; m+=12)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_loadu_pd(c0);
    c_0_1 = _mm256_loadu_pd(c1);
    c_0_2 = _mm256_loadu_pd(c2);
    c_1_0 = _mm256_loadu_pd(c0+4);
    c_1_1 = _mm256_loadu_pd(c1+4);
    c_1_2 = _mm256_loadu_pd(c2+4);
    c_2_0 = _mm256_loadu_pd(c0+8);
    c_2_1 = _mm256_loadu_pd(c1+8);
    c_2_2 = _mm256_loadu_pd(c2+8);

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_loadu_pd(a0);
      a0+=27;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

    _mm256_storeu_pd(c0, c_0_0);
    _mm256_storeu_pd(c1, c_0_1);
    _mm256_storeu_pd(c2, c_0_2);
    _mm256_storeu_pd(c0+4, c_1_0);
    _mm256_storeu_pd(c1+4, c_1_1);
    _mm256_storeu_pd(c2+4, c_1_2);
    _mm256_storeu_pd(c0+8, c_2_0);
    _mm256_storeu_pd(c1+8, c_2_1);
    _mm256_storeu_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
#ifdef __AVX2__
  for(int m = 32; m < 32; m+=8)
#else
  for(int m = 24; m < 32; m+=8)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_loadu_pd(c0);
    c_0_1 = _mm256_loadu_pd(c1);
    c_0_2 = _mm256_loadu_pd(c2);
    c_1_0 = _mm256_loadu_pd(c0+4);
    c_1_1 = _mm256_loadu_pd(c1+4);
    c_1_2 = _mm256_loadu_pd(c2+4);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_loadu_pd(a0);
      a0+=31;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

    _mm256_storeu_pd(c0, c_0_0);
    _mm256_storeu_pd(c1, c_0_1);
    _mm256_storeu_pd(c2, c_0_2);
    _mm256_storeu_pd(c0+4, c_1_0);
    _mm256_storeu_pd(c1+4, c_1_1);
    _mm256_storeu_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
#ifdef __AVX2__
  for(int m = 32; m < 32; m+=4)
#else
  for(int m = 32; m < 32; m+=4)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_loadu_pd(c0);
    c_0_1 = _mm256_loadu_pd(c1);
    c_0_2 = _mm256_loadu_pd(c2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_loadu_pd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

    _mm256_storeu_pd(c0, c_0_0);
    _mm256_storeu_pd(c1, c_0_1);
    _mm256_storeu_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
#ifdef __AVX2__
  for(int m = 32; m < 35; m++)
#else
  for(int m = 32; m < 35; m++)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0_128 = _mm_load_sd(c0);
    c_0_1_128 = _mm_load_sd(c1);
    c_0_2_128 = _mm_load_sd(c2);
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=35;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=70;
  c1+=70;
  c2+=70;
}

#endif

#if !defined(__SSE3__) && !defined(__AVX__)
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < 9; k++)
  {
    for(int m = 0; m < 35; m++)
    {
      C[(n*35)+m] += A[(k*35)+m] * B[(n*9)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 5670;
#endif

}

inline void generatedMatrixMultiplication_dense_56_9_56(double* A, double* B, double* C, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+56;
double* c2 = C+112;
for(int n = 0; n < 9; n+=3)
{
  for(int m = 0; m < 54; m+=6)
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
    c_2_0 = _mm_setzero_pd();
    c_2_1 = _mm_setzero_pd();
    c_2_2 = _mm_setzero_pd();

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    _mm_store_pd(c0+4, c_2_0);
    _mm_store_pd(c1+4, c_2_1);
    _mm_store_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  for(int m = 54; m < 54; m+=4)
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = 54; m < 56; m+=2)
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = 56; m < 56; m++)
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=112;
  c1+=112;
  c2+=112;
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+56;
double* c2 = C+112;
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  for(int m = 0; m < 48; m+=16)
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();
    c_3_0 = _mm256_setzero_pd();
    c_3_1 = _mm256_setzero_pd();
    c_3_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    _mm256_store_pd(c0+12, c_3_0);
    _mm256_store_pd(c1+12, c_3_1);
    _mm256_store_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  for(int m = 48; m < 48; m+=12)
#else
  for(int m = 0; m < 48; m+=12)
#endif
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
#ifdef __AVX2__
  for(int m = 48; m < 56; m+=8)
#else
  for(int m = 48; m < 56; m+=8)
#endif
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
#ifdef __AVX2__
  for(int m = 56; m < 56; m+=4)
#else
  for(int m = 56; m < 56; m+=4)
#endif
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
#ifdef __AVX2__
  for(int m = 56; m < 56; m++)
#else
  for(int m = 56; m < 56; m++)
#endif
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0_128 = _mm_setzero_pd();
    c_0_1_128 = _mm_setzero_pd();
    c_0_2_128 = _mm_setzero_pd();
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=112;
  c1+=112;
  c2+=112;
}

#endif

#if defined(__MIC__)
A_prefetch = A;
B_prefetch = B;
C_prefetch = C;

__m512d c_0;
__m512d c_1;
__m512d c_2;
__m512d c_3;
__m512d c_4;
__m512d c_5;
__m512d c_6;
__m512d c_7;
__m512d c_8;

__m512d b_bcst;

__m512d a_0;

#pragma prefetch C
for (int m = 0; m < 48; m += 8)
{
  c_0 = _mm512_setzero_pd();
  c_1 = _mm512_setzero_pd();
  c_2 = _mm512_setzero_pd();
  c_3 = _mm512_setzero_pd();
  c_4 = _mm512_setzero_pd();
  c_5 = _mm512_setzero_pd();
  c_6 = _mm512_setzero_pd();
  c_7 = _mm512_setzero_pd();
  c_8 = _mm512_setzero_pd();

  double* cur_A = A + m;
  double* cur_B = B;
  double* pre_B_L1 = B+8;

  #pragma noprefetch
  for (int k = 0; k < 56; k+=8)
  {
    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (0*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (1*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (2*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (3*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (4*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (5*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (6*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (7*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    _mm_prefetch((const char*)pre_B_L1 + (8*56), _MM_HINT_T0);
    pre_B_L1+=8;
    cur_B++;

  }

  _mm512_store_pd(C + m + 0*56, c_0);
  _mm512_store_pd(C + m + 1*56, c_1);
  _mm512_store_pd(C + m + 2*56, c_2);
  _mm512_store_pd(C + m + 3*56, c_3);
  _mm512_store_pd(C + m + 4*56, c_4);
  _mm512_store_pd(C + m + 5*56, c_5);
  _mm512_store_pd(C + m + 6*56, c_6);
  _mm512_store_pd(C + m + 7*56, c_7);
  _mm512_store_pd(C + m + 8*56, c_8);
}

int m = 48;

_mm_prefetch((const char*)C_prefetch + (0*56), _MM_HINT_T1);
c_0 = _mm512_setzero_pd();
_mm_prefetch((const char*)C_prefetch + (1*56), _MM_HINT_T1);
c_1 = _mm512_setzero_pd();
_mm_prefetch((const char*)C_prefetch + (2*56), _MM_HINT_T1);
c_2 = _mm512_setzero_pd();
_mm_prefetch((const char*)C_prefetch + (3*56), _MM_HINT_T1);
c_3 = _mm512_setzero_pd();
_mm_prefetch((const char*)C_prefetch + (4*56), _MM_HINT_T1);
c_4 = _mm512_setzero_pd();
_mm_prefetch((const char*)C_prefetch + (5*56), _MM_HINT_T1);
c_5 = _mm512_setzero_pd();
_mm_prefetch((const char*)C_prefetch + (6*56), _MM_HINT_T1);
c_6 = _mm512_setzero_pd();
_mm_prefetch((const char*)C_prefetch + (7*56), _MM_HINT_T1);
c_7 = _mm512_setzero_pd();
_mm_prefetch((const char*)C_prefetch + (8*56), _MM_HINT_T1);
c_8 = _mm512_setzero_pd();

double* cur_A = A + m;
double* cur_B = B;
double* pre_B_L1 = B+8;
double* pre_B_L2 = B_prefetch;
double* pre_A_L2 = A_prefetch;

#pragma noprefetch
for (int k = 0; k < 56; k+=8)
{
  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (0*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (0*56), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (1*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (1*56), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (2*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (2*56), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (3*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (3*56), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (4*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (4*56), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (5*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (5*56), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (6*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (6*56), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (7*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (7*56), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  _mm_prefetch((const char*)pre_B_L2 + (8*56), _MM_HINT_T1);
  b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  //_mm_prefetch((const char*)pre_B_L1 + (8*56), _MM_HINT_T0);
  //pre_B_L1+=8;
  pre_B_L2+=8;
  cur_B++;

}

//_mm_prefetch((const char*)C_prefetch + (0*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 0*56, c_0);
//_mm_prefetch((const char*)C_prefetch + (1*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 1*56, c_1);
//_mm_prefetch((const char*)C_prefetch + (2*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 2*56, c_2);
//_mm_prefetch((const char*)C_prefetch + (3*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 3*56, c_3);
//_mm_prefetch((const char*)C_prefetch + (4*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 4*56, c_4);
//_mm_prefetch((const char*)C_prefetch + (5*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 5*56, c_5);
//_mm_prefetch((const char*)C_prefetch + (6*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 6*56, c_6);
//_mm_prefetch((const char*)C_prefetch + (7*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 7*56, c_7);
//_mm_prefetch((const char*)C_prefetch + (8*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 8*56, c_8);

#endif

#if !defined(__SSE3__) && !defined(__AVX__) && !defined(__MIC__)
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < 56; k++)
  {
    for(int m = 0; m < 56; m++)
    {
      C[(n*56)+m] += A[(k*56)+m] * B[(n*56)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 56448;
#endif

}

inline void generatedMatrixMultiplication_denseAder_56_9_56(double* A, double* B, double* C, int exit_col, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+56;
double* c2 = C+112;
int M = 2;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 36;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 10;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 2;
    break;
}
for(int n = 0; n < 9; n+=3)
{
  int mDone, mDone_old;
  mDone = (M/6)*6;
  for(int m = 0; m < mDone; m+=6)
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
    c_2_0 = _mm_setzero_pd();
    c_2_1 = _mm_setzero_pd();
    c_2_2 = _mm_setzero_pd();

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_six_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      if ( __builtin_expect(exit_col == 10, false) ) { goto sse_six_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      if ( __builtin_expect(exit_col == 20, false) ) { goto sse_six_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      if ( __builtin_expect(exit_col == 35, false) ) { goto sse_six_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

sse_six_end:
    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    _mm_store_pd(c0+4, c_2_0);
    _mm_store_pd(c1+4, c_2_1);
    _mm_store_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/4)*4);
  for(int m = mDone_old; m < mDone; m+=4)
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
    c_1_0 = _mm_setzero_pd();
    c_1_1 = _mm_setzero_pd();
    c_1_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_four_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      if ( __builtin_expect(exit_col == 10, false) ) { goto sse_four_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      if ( __builtin_expect(exit_col == 20, false) ) { goto sse_four_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      if ( __builtin_expect(exit_col == 35, false) ) { goto sse_four_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

sse_four_end:
    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/2)*2);
  for(int m = mDone_old; m < mDone; m+=2)
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_two_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      if ( __builtin_expect(exit_col == 10, false) ) { goto sse_two_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      if ( __builtin_expect(exit_col == 20, false) ) { goto sse_two_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      if ( __builtin_expect(exit_col == 35, false) ) { goto sse_two_end; }
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

sse_two_end:
    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = mDone; m < M; m++)
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm_setzero_pd();
    c_0_1 = _mm_setzero_pd();
    c_0_2 = _mm_setzero_pd();
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      if ( __builtin_expect(exit_col == 4, false) ) { goto sse_one_end; }
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      if ( __builtin_expect(exit_col == 10, false) ) { goto sse_one_end; }
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      if ( __builtin_expect(exit_col == 20, false) ) { goto sse_one_end; }
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      if ( __builtin_expect(exit_col == 35, false) ) { goto sse_one_end; }
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

sse_one_end:
    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=(112+(56-M));
  c1+=(112+(56-M));
  c2+=(112+(56-M));
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+56;
double* c2 = C+112;
int M = 4;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 36;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 12;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 4;
    break;
}
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  int mDone, mDone_old;
  mDone = (M/16)*16;
  for(int m = 0; m < mDone; m+=16)
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();
    c_3_0 = _mm256_setzero_pd();
    c_3_1 = _mm256_setzero_pd();
    c_3_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_sixteen_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_sixteen_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      if ( __builtin_expect(exit_col == 20, false) ) { goto avx_sixteen_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      if ( __builtin_expect(exit_col == 35, false) ) { goto avx_sixteen_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
avx_sixteen_end:
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    _mm256_store_pd(c0+12, c_3_0);
    _mm256_store_pd(c1+12, c_3_1);
    _mm256_store_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/12)*12);
  for(int m = mDone_old; m < mDone; m+=12)
#else
  int mDone, mDone_old;
  mDone = (M/12)*12;
  for(int m = 0; m < mDone; m+=12)
#endif
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
    c_2_0 = _mm256_setzero_pd();
    c_2_1 = _mm256_setzero_pd();
    c_2_2 = _mm256_setzero_pd();

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_twelve_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_twelve_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      if ( __builtin_expect(exit_col == 20, false) ) { goto avx_twelve_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      if ( __builtin_expect(exit_col == 35, false) ) { goto avx_twelve_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

avx_twelve_end:
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/8)*8);
  for(int m = mDone_old; m < mDone; m+=8)
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
    c_1_0 = _mm256_setzero_pd();
    c_1_1 = _mm256_setzero_pd();
    c_1_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_eight_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_eight_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      if ( __builtin_expect(exit_col == 20, false) ) { goto avx_eight_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      if ( __builtin_expect(exit_col == 35, false) ) { goto avx_eight_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

avx_eight_end:
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
  mDone_old = mDone;
  mDone = mDone_old+(((M-mDone_old)/4)*4);
  for(int m = mDone_old; m < mDone; m+=4)
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0 = _mm256_setzero_pd();
    c_0_1 = _mm256_setzero_pd();
    c_0_2 = _mm256_setzero_pd();
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_four_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_four_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      if ( __builtin_expect(exit_col == 20, false) ) { goto avx_four_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      if ( __builtin_expect(exit_col == 35, false) ) { goto avx_four_end; }
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

avx_four_end:
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = mDone; m < M; m++)
  {
    double* b0 = B+(n*56);
    double* b1 = B+((n+1)*56);
    double* b2 = B+((n+2)*56);
    double* a0 = A+m;
    c_0_0_128 = _mm_setzero_pd();
    c_0_1_128 = _mm_setzero_pd();
    c_0_2_128 = _mm_setzero_pd();
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      if ( __builtin_expect(exit_col == 4, false) ) { goto avx_one_end; }
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      if ( __builtin_expect(exit_col == 10, false) ) { goto avx_one_end; }
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      if ( __builtin_expect(exit_col == 20, false) ) { goto avx_one_end; }
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      if ( __builtin_expect(exit_col == 35, false) ) { goto avx_one_end; }
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

avx_one_end:
    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=(112+(56-M));
  c1+=(112+(56-M));
  c2+=(112+(56-M));
}

#endif

#if defined(__MIC__)
int M = 8;
int K = 8;
switch(exit_col)
{
  case 84:
    M = 56;
    K = 84;
    break;
  case 56:
    M = 40;
    K = 56;
    break;
  case 35:
    M = 24;
    K = 40;
    break;
  case 20:
    M = 16;
    K = 24;
    break;
  case 10:
    M = 8;
    K = 16;
    break;
  case 4:
    M = 8;
    K = 8;
    break;
}
exit_col = K;

A_prefetch = A;
B_prefetch = B;
C_prefetch = C;

__m512d c_0;
__m512d c_1;
__m512d c_2;
__m512d c_3;
__m512d c_4;
__m512d c_5;
__m512d c_6;
__m512d c_7;
__m512d c_8;

__m512d b_bcst;

__m512d a_0;

#pragma prefetch C
for (int m = 0; m < M; m += 8)
{
  c_0 = _mm512_setzero_pd();
  c_1 = _mm512_setzero_pd();
  c_2 = _mm512_setzero_pd();
  c_3 = _mm512_setzero_pd();
  c_4 = _mm512_setzero_pd();
  c_5 = _mm512_setzero_pd();
  c_6 = _mm512_setzero_pd();
  c_7 = _mm512_setzero_pd();
  c_8 = _mm512_setzero_pd();

  double* cur_A = A + m;
  double* cur_B = B;
  double* pre_B_L1 = B+8;

  #pragma noprefetch
  for (int k = 0; k < exit_col; k+=8)
  {
    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (0*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (1*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (2*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (3*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (4*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (5*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (6*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)pre_B_L1 + (7*56), _MM_HINT_T0);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*56), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    _mm_prefetch((const char*)pre_B_L1 + (8*56), _MM_HINT_T0);
    pre_B_L1+=8;
    cur_B++;

  }

  _mm512_store_pd(C + m + 0*56, c_0);
  _mm512_store_pd(C + m + 1*56, c_1);
  _mm512_store_pd(C + m + 2*56, c_2);
  _mm512_store_pd(C + m + 3*56, c_3);
  _mm512_store_pd(C + m + 4*56, c_4);
  _mm512_store_pd(C + m + 5*56, c_5);
  _mm512_store_pd(C + m + 6*56, c_6);
  _mm512_store_pd(C + m + 7*56, c_7);
  _mm512_store_pd(C + m + 8*56, c_8);
}

#endif

#if !defined(__SSE3__) && !defined(__AVX__) && !defined(__MIC__)
int M = 4;
switch(exit_col)
{
  case 84:
    M = 56;
    break;
  case 56:
    M = 35;
    break;
  case 35:
    M = 20;
    break;
  case 20:
    M = 10;
    break;
  case 10:
    M = 4;
    break;
  case 4:
    M = 4;
    break;
}
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < exit_col; k++)
  {
    for(int m = 0; m < M; m++)
    {
      C[(n*56)+m] += A[(k*56)+m] * B[(n*56)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 18*M*exit_col;
#endif

}

inline void generatedMatrixMultiplication_dense_56_9_9(double* A, double* B, double* C, double* A_prefetch = NULL, double* B_prefetch = NULL, double* C_prefetch = NULL)
{
#if defined(__SSE3__) && !defined(__AVX__)
__m128d c_0_0;
__m128d c_0_1;
__m128d c_0_2;
__m128d c_1_0;
__m128d c_1_1;
__m128d c_1_2;
__m128d c_2_0;
__m128d c_2_1;
__m128d c_2_2;
__m128d b_0;
__m128d b_1;
__m128d b_2;
__m128d a_0;
__m128d a_1;
__m128d a_2;
#endif

#if defined(__SSE3__) && defined(__AVX__)
__m256d c_0_0;
__m256d c_0_1;
__m256d c_0_2;
__m256d c_1_0;
__m256d c_1_1;
__m256d c_1_2;
__m256d c_2_0;
__m256d c_2_1;
__m256d c_2_2;
__m256d c_3_0;
__m256d c_3_1;
__m256d c_3_2;
__m256d b_0;
__m256d b_1;
__m256d b_2;
__m256d a_0;
__m256d a_1;
__m256d a_2;
__m256d a_3;
__m128d b_0_128;
__m128d b_1_128;
__m128d b_2_128;
__m128d a_0_128;
__m128d a_1_128;
__m128d a_2_128;
__m128d c_0_0_128;
__m128d c_0_1_128;
__m128d c_0_2_128;
#endif

#if defined(__SSE3__) && !defined(__AVX__)
double* c0 = C;
double* c1 = C+56;
double* c2 = C+112;
for(int n = 0; n < 9; n+=3)
{
  for(int m = 0; m < 54; m+=6)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_pd(c0);
    c_0_1 = _mm_load_pd(c1);
    c_0_2 = _mm_load_pd(c2);
    c_1_0 = _mm_load_pd(c0+2);
    c_1_1 = _mm_load_pd(c1+2);
    c_1_2 = _mm_load_pd(c2+2);
    c_2_0 = _mm_load_pd(c0+4);
    c_2_1 = _mm_load_pd(c1+4);
    c_2_2 = _mm_load_pd(c2+4);

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=2;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      a_2 = _mm_load_pd(a0);
      a0+=52;
      c_2_0 = _mm_add_pd(c_2_0, _mm_mul_pd(a_2, b_0));
      c_2_1 = _mm_add_pd(c_2_1, _mm_mul_pd(a_2, b_1));
      c_2_2 = _mm_add_pd(c_2_2, _mm_mul_pd(a_2, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    _mm_store_pd(c0+4, c_2_0);
    _mm_store_pd(c1+4, c_2_1);
    _mm_store_pd(c2+4, c_2_2);
    c0+=6;
    c1+=6;
    c2+=6;
  }
  for(int m = 54; m < 54; m+=4)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_pd(c0);
    c_0_1 = _mm_load_pd(c1);
    c_0_2 = _mm_load_pd(c2);
    c_1_0 = _mm_load_pd(c0+2);
    c_1_1 = _mm_load_pd(c1+2);
    c_1_2 = _mm_load_pd(c2+2);
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=2;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      a_1 = _mm_load_pd(a0);
      a0+=54;
      c_1_0 = _mm_add_pd(c_1_0, _mm_mul_pd(a_1, b_0));
      c_1_1 = _mm_add_pd(c_1_1, _mm_mul_pd(a_1, b_1));
      c_1_2 = _mm_add_pd(c_1_2, _mm_mul_pd(a_1, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    _mm_store_pd(c0+2, c_1_0);
    _mm_store_pd(c1+2, c_1_1);
    _mm_store_pd(c2+2, c_1_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
  for(int m = 54; m < 56; m+=2)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_pd(c0);
    c_0_1 = _mm_load_pd(c1);
    c_0_2 = _mm_load_pd(c2);
      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

      b_0 = _mm_loaddup_pd(b0);
      b_1 = _mm_loaddup_pd(b1);
      b_2 = _mm_loaddup_pd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_pd(a0);
      a0+=56;
      c_0_0 = _mm_add_pd(c_0_0, _mm_mul_pd(a_0, b_0));
      c_0_1 = _mm_add_pd(c_0_1, _mm_mul_pd(a_0, b_1));
      c_0_2 = _mm_add_pd(c_0_2, _mm_mul_pd(a_0, b_2));

    _mm_store_pd(c0, c_0_0);
    _mm_store_pd(c1, c_0_1);
    _mm_store_pd(c2, c_0_2);
    c0+=2;
    c1+=2;
    c2+=2;
  }
  for(int m = 56; m < 56; m++)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm_load_sd(c0);
    c_0_1 = _mm_load_sd(c1);
    c_0_2 = _mm_load_sd(c2);
      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

      b_0 = _mm_load_sd(b0);
      b_1 = _mm_load_sd(b1);
      b_2 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm_load_sd(a0);
      a0+=56;
      c_0_0 = _mm_add_sd(c_0_0, _mm_mul_sd(a_0, b_0));
      c_0_1 = _mm_add_sd(c_0_1, _mm_mul_sd(a_0, b_1));
      c_0_2 = _mm_add_sd(c_0_2, _mm_mul_sd(a_0, b_2));

    _mm_store_sd(c0, c_0_0);
    _mm_store_sd(c1, c_0_1);
    _mm_store_sd(c2, c_0_2);
    c0++;
    c1++;
    c2++;
  }
  c0+=112;
  c1+=112;
  c2+=112;
}

#endif

#if defined(__SSE3__) && defined(__AVX__)
double* c0 = C;
double* c1 = C+56;
double* c2 = C+112;
for(int n = 0; n < 9; n+=3)
{
#ifdef __AVX2__
  for(int m = 0; m < 48; m+=16)
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
    c_1_0 = _mm256_load_pd(c0+4);
    c_1_1 = _mm256_load_pd(c1+4);
    c_1_2 = _mm256_load_pd(c2+4);
    c_2_0 = _mm256_load_pd(c0+8);
    c_2_1 = _mm256_load_pd(c1+8);
    c_2_2 = _mm256_load_pd(c2+8);
    c_3_0 = _mm256_load_pd(c0+12);
    c_3_1 = _mm256_load_pd(c1+12);
    c_3_2 = _mm256_load_pd(c2+12);

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
      a_1 = _mm256_load_pd(a0);
      a0+=4;
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
      a_2 = _mm256_load_pd(a0);
      a0+=4;
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
      a_3 = _mm256_load_pd(a0);
      a0+=44;
      c_3_0 = _mm256_fmadd_pd(a_3, b_0, c_3_0);
      c_3_1 = _mm256_fmadd_pd(a_3, b_1, c_3_1);
      c_3_2 = _mm256_fmadd_pd(a_3, b_2, c_3_2);
    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    _mm256_store_pd(c0+12, c_3_0);
    _mm256_store_pd(c1+12, c_3_1);
    _mm256_store_pd(c2+12, c_3_2);
    c0+=16;
    c1+=16;
    c2+=16;
  }
#endif
#ifdef __AVX2__
  for(int m = 48; m < 48; m+=12)
#else
  for(int m = 0; m < 48; m+=12)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
    c_1_0 = _mm256_load_pd(c0+4);
    c_1_1 = _mm256_load_pd(c1+4);
    c_1_2 = _mm256_load_pd(c2+4);
    c_2_0 = _mm256_load_pd(c0+8);
    c_2_1 = _mm256_load_pd(c1+8);
    c_2_2 = _mm256_load_pd(c2+8);

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      a_2 = _mm256_load_pd(a0);
      a0+=48;
#ifdef __AVX2__
      c_2_0 = _mm256_fmadd_pd(a_2, b_0, c_2_0);
      c_2_1 = _mm256_fmadd_pd(a_2, b_1, c_2_1);
      c_2_2 = _mm256_fmadd_pd(a_2, b_2, c_2_2);
#else
      c_2_0 = _mm256_add_pd(c_2_0, _mm256_mul_pd(a_2, b_0));
      c_2_1 = _mm256_add_pd(c_2_1, _mm256_mul_pd(a_2, b_1));
      c_2_2 = _mm256_add_pd(c_2_2, _mm256_mul_pd(a_2, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    _mm256_store_pd(c0+8, c_2_0);
    _mm256_store_pd(c1+8, c_2_1);
    _mm256_store_pd(c2+8, c_2_2);
    c0+=12;
    c1+=12;
    c2+=12;
  }
#ifdef __AVX2__
  for(int m = 48; m < 56; m+=8)
#else
  for(int m = 48; m < 56; m+=8)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
    c_1_0 = _mm256_load_pd(c0+4);
    c_1_1 = _mm256_load_pd(c1+4);
    c_1_2 = _mm256_load_pd(c2+4);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=4;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      a_1 = _mm256_load_pd(a0);
      a0+=52;
#ifdef __AVX2__
      c_1_0 = _mm256_fmadd_pd(a_1, b_0, c_1_0);
      c_1_1 = _mm256_fmadd_pd(a_1, b_1, c_1_1);
      c_1_2 = _mm256_fmadd_pd(a_1, b_2, c_1_2);
#else
      c_1_0 = _mm256_add_pd(c_1_0, _mm256_mul_pd(a_1, b_0));
      c_1_1 = _mm256_add_pd(c_1_1, _mm256_mul_pd(a_1, b_1));
      c_1_2 = _mm256_add_pd(c_1_2, _mm256_mul_pd(a_1, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    _mm256_store_pd(c0+4, c_1_0);
    _mm256_store_pd(c1+4, c_1_1);
    _mm256_store_pd(c2+4, c_1_2);
    c0+=8;
    c1+=8;
    c2+=8;
  }
#ifdef __AVX2__
  for(int m = 56; m < 56; m+=4)
#else
  for(int m = 56; m < 56; m+=4)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0 = _mm256_load_pd(c0);
    c_0_1 = _mm256_load_pd(c1);
    c_0_2 = _mm256_load_pd(c2);
      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

      b_0 = _mm256_broadcast_sd(b0);
      b_1 = _mm256_broadcast_sd(b1);
      b_2 = _mm256_broadcast_sd(b2);

      b0++; b1++; b2++;

      a_0 = _mm256_load_pd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0 = _mm256_fmadd_pd(a_0, b_0, c_0_0);
      c_0_1 = _mm256_fmadd_pd(a_0, b_1, c_0_1);
      c_0_2 = _mm256_fmadd_pd(a_0, b_2, c_0_2);
#else
      c_0_0 = _mm256_add_pd(c_0_0, _mm256_mul_pd(a_0, b_0));
      c_0_1 = _mm256_add_pd(c_0_1, _mm256_mul_pd(a_0, b_1));
      c_0_2 = _mm256_add_pd(c_0_2, _mm256_mul_pd(a_0, b_2));
#endif

    _mm256_store_pd(c0, c_0_0);
    _mm256_store_pd(c1, c_0_1);
    _mm256_store_pd(c2, c_0_2);
    c0+=4;
    c1+=4;
    c2+=4;
  }
#ifdef __AVX2__
  for(int m = 56; m < 56; m++)
#else
  for(int m = 56; m < 56; m++)
#endif
  {
    double* b0 = B+(n*9);
    double* b1 = B+((n+1)*9);
    double* b2 = B+((n+2)*9);
    double* a0 = A+m;
    c_0_0_128 = _mm_load_sd(c0);
    c_0_1_128 = _mm_load_sd(c1);
    c_0_2_128 = _mm_load_sd(c2);
      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

      b_0_128 = _mm_load_sd(b0);
      b_1_128 = _mm_load_sd(b1);
      b_2_128 = _mm_load_sd(b2);

      b0++; b1++; b2++;

      a_0_128 = _mm_load_sd(a0);
      a0+=56;
#ifdef __AVX2__
      c_0_0_128 = _mm_fmadd_sd(a_0_128, b_0_128, c_0_0_128);
      c_0_1_128 = _mm_fmadd_sd(a_0_128, b_1_128, c_0_1_128);
      c_0_2_128 = _mm_fmadd_sd(a_0_128, b_2_128, c_0_2_128);
#else
      c_0_0_128 = _mm_add_sd(c_0_0_128, _mm_mul_sd(a_0_128, b_0_128));
      c_0_1_128 = _mm_add_sd(c_0_1_128, _mm_mul_sd(a_0_128, b_1_128));
      c_0_2_128 = _mm_add_sd(c_0_2_128, _mm_mul_sd(a_0_128, b_2_128));
#endif

    _mm_store_sd(c0, c_0_0_128);
    _mm_store_sd(c1, c_0_1_128);
    _mm_store_sd(c2, c_0_2_128);
    c0+=1;
    c1+=1;
    c2+=1;
  }
  c0+=112;
  c1+=112;
  c2+=112;
}

#endif

#if defined(__MIC__)
A_prefetch = A;
B_prefetch = B;
C_prefetch = C;

__m512d c_0;
__m512d c_1;
__m512d c_2;
__m512d c_3;
__m512d c_4;
__m512d c_5;
__m512d c_6;
__m512d c_7;
__m512d c_8;

__m512d b_bcst;

__m512d a_0;

#pragma prefetch C
for (int m = 0; m < 48; m += 8)
{
  c_0 = _mm512_load_pd(C + m + 0*56);
  c_1 = _mm512_load_pd(C + m + 1*56);
  c_2 = _mm512_load_pd(C + m + 2*56);
  c_3 = _mm512_load_pd(C + m + 3*56);
  c_4 = _mm512_load_pd(C + m + 4*56);
  c_5 = _mm512_load_pd(C + m + 5*56);
  c_6 = _mm512_load_pd(C + m + 6*56);
  c_7 = _mm512_load_pd(C + m + 7*56);
  c_8 = _mm512_load_pd(C + m + 8*56);

  double* cur_A = A + m;
  double* cur_B = B;
  double* pre_B_L1 = B+8;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

    _mm_prefetch((const char*) (cur_A + 8), _MM_HINT_T1);
    a_0 = _mm512_load_pd(cur_A);
    cur_A += 56;
    b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
    b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
    c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
    b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
    b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
    b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
    b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
    b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
    b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
    b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
    c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
    cur_B++;

  _mm512_store_pd(C + m + 0*56, c_0);
  _mm512_store_pd(C + m + 1*56, c_1);
  _mm512_store_pd(C + m + 2*56, c_2);
  _mm512_store_pd(C + m + 3*56, c_3);
  _mm512_store_pd(C + m + 4*56, c_4);
  _mm512_store_pd(C + m + 5*56, c_5);
  _mm512_store_pd(C + m + 6*56, c_6);
  _mm512_store_pd(C + m + 7*56, c_7);
  _mm512_store_pd(C + m + 8*56, c_8);
}

int m = 48;

_mm_prefetch((const char*)C_prefetch + (0*56), _MM_HINT_T1);
c_0 = _mm512_load_pd(C + m + 0*56);
_mm_prefetch((const char*)C_prefetch + (1*56), _MM_HINT_T1);
c_1 = _mm512_load_pd(C + m + 1*56);
_mm_prefetch((const char*)C_prefetch + (2*56), _MM_HINT_T1);
c_2 = _mm512_load_pd(C + m + 2*56);
_mm_prefetch((const char*)C_prefetch + (3*56), _MM_HINT_T1);
c_3 = _mm512_load_pd(C + m + 3*56);
_mm_prefetch((const char*)C_prefetch + (4*56), _MM_HINT_T1);
c_4 = _mm512_load_pd(C + m + 4*56);
_mm_prefetch((const char*)C_prefetch + (5*56), _MM_HINT_T1);
c_5 = _mm512_load_pd(C + m + 5*56);
_mm_prefetch((const char*)C_prefetch + (6*56), _MM_HINT_T1);
c_6 = _mm512_load_pd(C + m + 6*56);
_mm_prefetch((const char*)C_prefetch + (7*56), _MM_HINT_T1);
c_7 = _mm512_load_pd(C + m + 7*56);
_mm_prefetch((const char*)C_prefetch + (8*56), _MM_HINT_T1);
c_8 = _mm512_load_pd(C + m + 8*56);

double* cur_A = A + m;
double* cur_B = B;
double* pre_B_L1 = B+8;
double* pre_B_L2 = B_prefetch;
double* pre_A_L2 = A_prefetch;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (0*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (0*9), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (1*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (1*9), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (2*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (2*9), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (3*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (3*9), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (4*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (4*9), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (5*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (5*9), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (6*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (6*9), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (7*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (7*9), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  _mm_prefetch((const char*)pre_B_L2 + (8*56), _MM_HINT_T1);
  b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  //_mm_prefetch((const char*)pre_B_L1 + (8*9), _MM_HINT_T0);
  //pre_B_L1+=8;
  pre_B_L2+=8;
  cur_B++;

  _mm_prefetch((const char*)pre_A_L2, _MM_HINT_T2);
  a_0 = _mm512_load_pd(cur_A);
  cur_A += 56;
  pre_A_L2 += 56;
  b_bcst = _mm512_extload_pd(cur_B + (0*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_0 = _mm512_fmadd_pd(a_0, b_bcst, c_0);
  b_bcst = _mm512_extload_pd(cur_B + (1*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)cur_A, _MM_HINT_T0);
  c_1 = _mm512_fmadd_pd(a_0, b_bcst, c_1);
  b_bcst = _mm512_extload_pd(cur_B + (2*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_2 = _mm512_fmadd_pd(a_0, b_bcst, c_2);
  b_bcst = _mm512_extload_pd(cur_B + (3*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  _mm_prefetch((const char*)pre_B_L2 + (0*56), _MM_HINT_T1);
  c_3 = _mm512_fmadd_pd(a_0, b_bcst, c_3);
  b_bcst = _mm512_extload_pd(cur_B + (4*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_4 = _mm512_fmadd_pd(a_0, b_bcst, c_4);
  b_bcst = _mm512_extload_pd(cur_B + (5*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  //_mm_prefetch((const char*)pre_B_L1 + (0*9), _MM_HINT_T0);
  c_5 = _mm512_fmadd_pd(a_0, b_bcst, c_5);
  b_bcst = _mm512_extload_pd(cur_B + (6*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_6 = _mm512_fmadd_pd(a_0, b_bcst, c_6);
  b_bcst = _mm512_extload_pd(cur_B + (7*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_7 = _mm512_fmadd_pd(a_0, b_bcst, c_7);
  b_bcst = _mm512_extload_pd(cur_B + (8*9), _MM_UPCONV_PD_NONE, _MM_BROADCAST_1X8, _MM_HINT_NONE);
  c_8 = _mm512_fmadd_pd(a_0, b_bcst, c_8);
  cur_B++;

//_mm_prefetch((const char*)C_prefetch + (0*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 0*56, c_0);
//_mm_prefetch((const char*)C_prefetch + (1*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 1*56, c_1);
//_mm_prefetch((const char*)C_prefetch + (2*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 2*56, c_2);
//_mm_prefetch((const char*)C_prefetch + (3*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 3*56, c_3);
//_mm_prefetch((const char*)C_prefetch + (4*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 4*56, c_4);
//_mm_prefetch((const char*)C_prefetch + (5*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 5*56, c_5);
//_mm_prefetch((const char*)C_prefetch + (6*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 6*56, c_6);
//_mm_prefetch((const char*)C_prefetch + (7*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 7*56, c_7);
//_mm_prefetch((const char*)C_prefetch + (8*56), _MM_HINT_T0);
_mm512_store_pd(C + m + 8*56, c_8);

#endif

#if !defined(__SSE3__) && !defined(__AVX__) && !defined(__MIC__)
for (int n = 0; n < 9; n++)
{
  for (int k = 0; k < 9; k++)
  {
    for(int m = 0; m < 56; m++)
    {
      C[(n*56)+m] += A[(k*56)+m] * B[(n*9)+k];
    }
  }
}
#endif

#ifndef NDEBUG
num_flops += 9072;
#endif

}


#endif